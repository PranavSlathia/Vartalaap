<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Vartalaap Voice Bot</title>
    <style>
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            min-height: 100vh;
            color: #fff;
        }
        .container {
            max-width: 600px;
            margin: 0 auto;
            padding: 20px;
        }
        header {
            text-align: center;
            padding: 30px 0;
        }
        header h1 {
            font-size: 28px;
            margin-bottom: 8px;
        }
        header p {
            color: #888;
            font-size: 14px;
        }
        .chat-container {
            background: #1e1e30;
            border-radius: 16px;
            padding: 20px;
            min-height: 350px;
            max-height: 400px;
            overflow-y: auto;
            margin-bottom: 20px;
        }
        .message {
            margin-bottom: 16px;
            display: flex;
            flex-direction: column;
        }
        .message.user { align-items: flex-end; }
        .message.bot { align-items: flex-start; }
        .message-content {
            max-width: 85%;
            padding: 12px 16px;
            border-radius: 16px;
            font-size: 15px;
            line-height: 1.5;
        }
        .message.user .message-content {
            background: #4f46e5;
            border-bottom-right-radius: 4px;
        }
        .message.bot .message-content {
            background: #2d2d44;
            border-bottom-left-radius: 4px;
        }
        .message-meta {
            font-size: 11px;
            color: #666;
            margin-top: 4px;
        }

        /* Voice indicator */
        .voice-indicator {
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 30px;
        }
        .orb {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            background: #333;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.3s ease;
            cursor: pointer;
            position: relative;
        }
        .orb-inner {
            width: 100px;
            height: 100px;
            border-radius: 50%;
            background: #444;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 13px;
            font-weight: 600;
            text-align: center;
            line-height: 1.3;
            transition: all 0.3s ease;
        }

        /* States */
        .orb.idle { background: #374151; }
        .orb.idle .orb-inner { background: #4b5563; }

        .orb.listening {
            background: #22c55e;
            box-shadow: 0 0 30px rgba(34, 197, 94, 0.5);
            animation: pulse-green 1.5s infinite;
        }
        .orb.listening .orb-inner { background: #16a34a; }

        .orb.processing {
            background: #f59e0b;
            animation: pulse-yellow 1s infinite;
        }
        .orb.processing .orb-inner { background: #d97706; }

        .orb.speaking {
            background: #3b82f6;
            box-shadow: 0 0 30px rgba(59, 130, 246, 0.5);
            animation: pulse-blue 0.8s infinite;
        }
        .orb.speaking .orb-inner { background: #2563eb; }

        @keyframes pulse-green {
            0%, 100% { box-shadow: 0 0 20px rgba(34, 197, 94, 0.4); transform: scale(1); }
            50% { box-shadow: 0 0 40px rgba(34, 197, 94, 0.6); transform: scale(1.02); }
        }
        @keyframes pulse-yellow {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }
        @keyframes pulse-blue {
            0%, 100% { box-shadow: 0 0 20px rgba(59, 130, 246, 0.4); }
            50% { box-shadow: 0 0 40px rgba(59, 130, 246, 0.6); }
        }

        .status-text {
            margin-top: 20px;
            font-size: 14px;
            color: #888;
            text-align: center;
        }
        .status-text.active { color: #22c55e; }
        .status-text.error { color: #ef4444; }

        /* Volume visualization */
        .volume-bars {
            display: flex;
            gap: 3px;
            height: 30px;
            align-items: flex-end;
            margin-top: 15px;
        }
        .volume-bar {
            width: 4px;
            background: #22c55e;
            border-radius: 2px;
            transition: height 0.05s ease;
        }

        /* Controls */
        .controls {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin-top: 20px;
        }
        .btn {
            padding: 10px 24px;
            border-radius: 8px;
            border: none;
            font-size: 14px;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.2s;
        }
        .btn-primary {
            background: #4f46e5;
            color: white;
        }
        .btn-primary:hover { background: #4338ca; }
        .btn-primary:disabled { background: #666; cursor: not-allowed; }
        .btn-secondary {
            background: #374151;
            color: white;
        }
        .btn-secondary:hover { background: #4b5563; }

        /* Hidden audio player */
        #audioPlayer { display: none; }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>üçΩÔ∏è Himalayan Kitchen</h1>
            <p>Voice Assistant - Hands-free conversation</p>
        </header>

        <div class="chat-container" id="chat"></div>

        <div class="voice-indicator">
            <div class="orb idle" id="orb" onclick="handleOrbClick()">
                <div class="orb-inner" id="orbText">Click to<br>Start</div>
            </div>
            <div class="volume-bars" id="volumeBars" style="display: none;">
                <div class="volume-bar" style="height: 5px;"></div>
                <div class="volume-bar" style="height: 5px;"></div>
                <div class="volume-bar" style="height: 5px;"></div>
                <div class="volume-bar" style="height: 5px;"></div>
                <div class="volume-bar" style="height: 5px;"></div>
                <div class="volume-bar" style="height: 5px;"></div>
                <div class="volume-bar" style="height: 5px;"></div>
                <div class="volume-bar" style="height: 5px;"></div>
            </div>
            <div class="status-text" id="status">Click to start conversation</div>
        </div>

        <div class="controls">
            <button class="btn btn-secondary" onclick="resetConversation()">Reset</button>
            <button class="btn btn-primary" id="toggleBtn" onclick="toggleConversation()">Start Call</button>
        </div>
    </div>

    <audio id="audioPlayer"></audio>

    <script>
        // State
        let isActive = false;
        let isListening = false;
        let isProcessing = false;
        let isSpeaking = false;
        let sessionId = Date.now().toString();

        // Audio
        let mediaRecorder;
        let audioChunks = [];
        let audioContext;
        let analyser;
        let mediaStream;
        let silenceTimer;
        let hasSpoken = false;

        // Settings
        const SILENCE_THRESHOLD = 0.015;
        const SILENCE_DURATION = 1200;  // 1.2 seconds
        const MIN_SPEECH_TIME = 300;

        // Elements
        const orb = document.getElementById('orb');
        const orbText = document.getElementById('orbText');
        const status = document.getElementById('status');
        const chat = document.getElementById('chat');
        const volumeBars = document.getElementById('volumeBars');
        const toggleBtn = document.getElementById('toggleBtn');
        const audioPlayer = document.getElementById('audioPlayer');
        const bars = volumeBars.querySelectorAll('.volume-bar');

        // Audio player events
        audioPlayer.onended = () => {
            isSpeaking = false;
            if (isActive) {
                // Auto-start listening after bot finishes speaking
                setTimeout(() => startListening(), 300);
            } else {
                setIdleState();
            }
        };

        audioPlayer.onerror = () => {
            isSpeaking = false;
            if (isActive) {
                setTimeout(() => startListening(), 300);
            }
        };

        function handleOrbClick() {
            if (!isActive) {
                startConversation();
            }
        }

        function toggleConversation() {
            if (isActive) {
                stopConversation();
            } else {
                startConversation();
            }
        }

        async function startConversation() {
            try {
                // Request mic permission first
                mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });

                isActive = true;
                toggleBtn.textContent = 'End Call';

                // Play greeting and then start listening
                setProcessingState();
                status.textContent = 'Starting conversation...';

                // Generate and play greeting
                const greeting = "Namaste! Himalayan Kitchen mein aapka swagat hai. Main aapki kya madad kar sakti hoon?";
                addMessage('bot', greeting);

                const audioUrl = await generateTTS(greeting);
                if (audioUrl) {
                    playSpeech(audioUrl);
                } else {
                    // If TTS fails, just start listening
                    startListening();
                }

            } catch (err) {
                console.error('Mic error:', err);
                status.textContent = 'Microphone access denied';
                status.className = 'status-text error';
            }
        }

        function stopConversation() {
            isActive = false;
            stopListening();
            audioPlayer.pause();
            if (mediaStream) {
                mediaStream.getTracks().forEach(t => t.stop());
            }
            setIdleState();
            toggleBtn.textContent = 'Start Call';
            status.textContent = 'Call ended. Click to restart.';
        }

        function resetConversation() {
            stopConversation();
            sessionId = Date.now().toString();
            chat.innerHTML = '';
            status.textContent = 'Click to start conversation';
        }

        // States
        function setIdleState() {
            orb.className = 'orb idle';
            orbText.innerHTML = 'Click to<br>Start';
            volumeBars.style.display = 'none';
        }

        function setListeningState() {
            orb.className = 'orb listening';
            orbText.innerHTML = 'Listening...';
            volumeBars.style.display = 'flex';
            status.textContent = 'Speak now...';
            status.className = 'status-text active';
        }

        function setProcessingState() {
            orb.className = 'orb processing';
            orbText.innerHTML = 'Processing...';
            volumeBars.style.display = 'none';
            status.textContent = 'Processing...';
            status.className = 'status-text';
        }

        function setSpeakingState() {
            orb.className = 'orb speaking';
            orbText.innerHTML = 'Speaking...';
            volumeBars.style.display = 'none';
            status.textContent = 'Bot is speaking...';
            status.className = 'status-text';
        }

        // Listening
        async function startListening() {
            if (isListening || !isActive) return;

            try {
                // Reuse existing stream or get new one
                if (!mediaStream || mediaStream.getTracks()[0].readyState === 'ended') {
                    mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                }

                audioContext = new AudioContext();
                const source = audioContext.createMediaStreamSource(mediaStream);
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
                source.connect(analyser);

                mediaRecorder = new MediaRecorder(mediaStream, { mimeType: 'audio/webm' });
                audioChunks = [];
                hasSpoken = false;

                mediaRecorder.ondataavailable = (e) => {
                    if (e.data.size > 0) audioChunks.push(e.data);
                };

                mediaRecorder.onstop = async () => {
                    if (audioContext) audioContext.close();

                    if (audioChunks.length > 0 && hasSpoken) {
                        const blob = new Blob(audioChunks, { type: 'audio/webm' });
                        await processAudio(blob);
                    } else if (isActive) {
                        // No speech detected, keep listening
                        startListening();
                    }
                };

                mediaRecorder.start(100);
                isListening = true;
                setListeningState();
                monitorVolume();

            } catch (err) {
                console.error('Listen error:', err);
                status.textContent = 'Microphone error: ' + err.message;
                status.className = 'status-text error';
            }
        }

        function stopListening() {
            if (!isListening) return;

            isListening = false;
            if (silenceTimer) {
                clearTimeout(silenceTimer);
                silenceTimer = null;
            }

            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
            }
        }

        function monitorVolume() {
            if (!isListening || !analyser) return;

            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            const startTime = Date.now();

            function check() {
                if (!isListening) return;

                analyser.getByteFrequencyData(dataArray);

                // Calculate volume
                let sum = 0;
                for (let i = 0; i < dataArray.length; i++) {
                    sum += dataArray[i];
                }
                const volume = sum / dataArray.length / 255;

                // Update volume bars
                updateVolumeBars(volume);

                // Detect speech
                if (volume > SILENCE_THRESHOLD) {
                    hasSpoken = true;
                    orbText.innerHTML = 'Speaking...';

                    if (silenceTimer) {
                        clearTimeout(silenceTimer);
                        silenceTimer = null;
                    }
                } else if (hasSpoken && !silenceTimer) {
                    // User stopped speaking, start silence timer
                    const elapsed = Date.now() - startTime;
                    if (elapsed > MIN_SPEECH_TIME) {
                        silenceTimer = setTimeout(() => {
                            stopListening();
                        }, SILENCE_DURATION);
                    }
                }

                // Max recording time: 30 seconds
                if (Date.now() - startTime > 30000) {
                    stopListening();
                    return;
                }

                requestAnimationFrame(check);
            }

            check();
        }

        function updateVolumeBars(volume) {
            const scaled = Math.min(volume * 4, 1);
            bars.forEach((bar, i) => {
                const height = 5 + (scaled * 25 * (1 + Math.sin(Date.now() / 100 + i)));
                bar.style.height = height + 'px';
            });
        }

        // Process audio
        async function processAudio(blob) {
            isProcessing = true;
            setProcessingState();

            try {
                const formData = new FormData();
                formData.append('audio', blob, 'recording.webm');
                formData.append('session_id', sessionId);

                const response = await fetch('/api/voice/process', {
                    method: 'POST',
                    body: formData
                });

                const data = await response.json();

                if (data.transcript) {
                    addMessage('user', data.transcript);
                }

                if (data.response) {
                    addMessage('bot', data.response);

                    if (data.audio_url) {
                        playSpeech(data.audio_url);
                    } else {
                        // No audio, start listening again
                        if (isActive) startListening();
                    }
                } else if (data.error) {
                    status.textContent = data.error;
                    status.className = 'status-text error';
                    if (isActive) setTimeout(() => startListening(), 1000);
                } else {
                    if (isActive) startListening();
                }

            } catch (err) {
                console.error('Process error:', err);
                status.textContent = 'Error: ' + err.message;
                status.className = 'status-text error';
                if (isActive) setTimeout(() => startListening(), 1000);
            } finally {
                isProcessing = false;
            }
        }

        // TTS
        async function generateTTS(text) {
            try {
                const response = await fetch('/api/voice/tts', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ text })
                });
                const data = await response.json();
                return data.audio_url;
            } catch (err) {
                console.error('TTS error:', err);
                return null;
            }
        }

        function playSpeech(url) {
            isSpeaking = true;
            setSpeakingState();
            audioPlayer.src = url;
            audioPlayer.play().catch(err => {
                console.error('Play error:', err);
                isSpeaking = false;
                if (isActive) startListening();
            });
        }

        // Messages
        function addMessage(role, text) {
            const div = document.createElement('div');
            div.className = `message ${role}`;
            div.innerHTML = `
                <div class="message-content">${escapeHtml(text)}</div>
                <div class="message-meta">${new Date().toLocaleTimeString()}</div>
            `;
            chat.appendChild(div);
            chat.scrollTop = chat.scrollHeight;
        }

        function escapeHtml(text) {
            const div = document.createElement('div');
            div.textContent = text;
            return div.innerHTML;
        }
    </script>
</body>
</html>
